


<div id="tips" class="section level1">
<h1>Tips</h1>
<p>Below are tips and links to resources from the Regional Monitoring
Network (RMN) project. To date, RMN partners have worked primarily with
thermal and hydrologic data, and more recently, with dissolved oxygen
data from lakes. The data are typically downloaded 2-4 times a year
(i.e., the data used are not ‘real-time’ data).</p>
<div id="site-visits" class="section level2">
<h2>Site visits</h2>
<p>It helps speed up the Quality Control (QC) process if you follow a
checklist during site visits and document anything that might affect the
quality of the data (e.g., sensor out of water or buried in sediment,
beaver activity, low battery).</p>
<ul>
<li><strong>Resource:</strong> <a href="SiteVisitChecklist.zip">Site
visit checklist</a> [ZIP]</li>
</ul>
</div>
<div id="sensor-configuration" class="section level2">
<h2>Sensor configuration</h2>
<p>Some people have had problems with air and water sensors being out of
sync ( e.g., one records at 11:00 and the other records at 11:07). If
you are deploying air and water sensors at a site, make sure you
configure them so that they are recording at the same time. This will
make data processing faster and easier.</p>
<ul>
<li><strong>Resource:</strong> <a href="HOBO_ConfigLaunch_20170803.pdf">Onset HOBO configuration tips</a>
[PDF]</li>
</ul>
<p>Another issue that sometimes occurs is data overlap (where more than
one file has measurements covering part of the same time periods). Make
sure you clear the sensor’s memory when you download data and relaunch
sensors to avoid overlapping data.</p>
<ul>
<li><strong>Resource:</strong> <a href="HOBO_DataDownload_20170823.pdf">Onset HOBO download and relaunch
tips</a> [PDF]</li>
</ul>
</div>
<div id="qc-workflow" class="section level2">
<h2>QC workflow</h2>
<p>There are generally two QC workflow scenarios: 1) users QC their data
after each download and work with one file per site at a time; or 2)
users have a backlog of data that cover multiple deployment periods that
they aggregate into one file before performing QC.</p>
<ul>
<li><strong>Resources:</strong> Suggested workflows for each scenario:
<ul>
<li><a href="Workflow_QC_report_20220824.pdf">Single file</a> [PDF]</li>
<li><a href="Workflow_DataPileup_20220824.pdf">Multiple files</a>
[PDF]</li>
</ul></li>
</ul>
</div>
<div id="data-edits" class="section level2">
<h2>Data edits</h2>
<p>When reviewing the QC reports, it is important to be consistent in
how you handle flagged data. Here is an example approach:</p>
<ul>
<li><p>If you are certain a data point is erroneous, delete the
measurement and flag as ‘F’. If you are not sure, flag the data point as
‘S’ and do not delete. Let the people using the data decide whether to
remove questionable measurements from their analysis.</p></li>
<li><p>Document that you checked each point flagged as ‘F’ and ‘S’ by
adding a note or data qualifier to the Comment column.</p></li>
<li><p>Leave cells with missing data as they are (i.e., do not delete
them).</p></li>
<li><p><strong>Resource:</strong> <a href="DataQualifiers_20220210.xlsx">List of example data qualifiers</a>
[XLSX]</p></li>
</ul>
</div>
<div id="accuracy-checks" class="section level2">
<h2>Accuracy checks</h2>
<p>Accuracy checks are comparisons of discrete or in situ measurements
taken in the lab and/or in the field with sensor measurements from the
closest date/time. The difference between the sensor and discrete
measurements should be within the accuracy quoted by the manufacturer
(e.g., ±0.2°C if you are using the Onset HOBO proV2 sensor).</p>
<ul>
<li><strong>Resource:</strong> <a href="EXAMPLE_AccuracyCheckWkst.xlsx">Example accuracy check
worksheet</a> [XLSX]</li>
</ul>
</div>
<div id="visual-checks-of-time-series-plots" class="section level2">
<h2>Visual checks of time series plots</h2>
<p>Visual checks of time series plots are an important part of the QC
process. Some issues, such as dewatering, sediment burial, ice cover,
and beaver activity, show fairly common patterns and we’ve been
compiling examples of these patterns to help people recognize potential
QC issues with their data.</p>
<ul>
<li><strong>Resource:</strong> <a href="PlotQC_WatchList_20220824.pdf">Visual checks</a> [PDF]</li>
</ul>
</div>
<div id="checking-sensor-data-against-other-data-sources" class="section level2">
<h2>Checking sensor data against other data sources</h2>
<p>Some partners have been downloading data from nearby weather stations
and USGS gages, as well as modeled air temperature and precipitation
data from sources such as Daymet
(<a class="menu__link" href="https://daymet.ornl.gov/getdata" target="_blank">Daymet<span class="usa-tag external-link__tag" title="Exit EPA Website"> <span aria-hidden="true">Exit</span> <span class="u-visually-hidden"> Exit EPA
Website</span> </span> </a>), and comparing those data to sensor
measurements as part of their QC process.</p>
<ul>
<li><strong>Resource:</strong> <a href="Daymet_Wx_Gage.zip">Daymet or
USGS gage check</a> [ZIP]</li>
</ul>
</div>
<div id="troubleshooting" class="section level2">
<h2>Troubleshooting</h2>
<p>This tab in the ContDataQC shows output from the R console when
running the QC, aggregating, summarizing, and USGS data retrieval
processes. This information could be used to help understand and
troubleshot why there might be an error or issue with the
application.</p>
</div>
</div>
