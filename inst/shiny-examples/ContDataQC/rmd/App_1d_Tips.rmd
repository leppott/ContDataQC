---
title: "Main Functions 5c"
date: "`r format(Sys.time(), '%Y-%m-%d %H:%M:%S')`"
always_allow_html: true
output:
  html_fragment:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(results='asis', echo=FALSE, warning=FALSE, message = FALSE)
# needed for trouble shooting
boo_DEBUG <- FALSE
if(boo_DEBUG==TRUE){
  # myConfig <- file.path(system.file(package="ContDataQC"), "extdata", "config.ORIG.R")
  # source(myConfig)
}## IF ~ boo_DEBUG ~ END
```

# QC Tips

Below are instructional materials and links to resources we have compiled as we 
continue to gain experience QCing continuous data. To date, we have worked 
primarily with thermal and hydrologic data, and more recently, dissolved oxygen 
data from lakes. The data are typically downloaded 2-4 times a year. We have not
worked with ‘real-time’ data.

If you have any questions, feedback on ways to improve this process or 
suggestions on additional materials that you feel would be helpful to share, 
please contact Jen Stamp (Jen.Stamp@tetratech.com).

## Data corrections

If you are processing data for the RMNs, we are currently recommending the 
following approach 

*	If you are certain a data point is erroneous, delete the measurement and flag 
as ‘F’. If you are not sure, flag the data as ‘S’ and do not delete. Let the 
people using the data decide whether to remove questionable measurements from 
their analysis. 

*	Document that you checked each point flagged as ‘F’ and ‘S’ by adding a data 
qualifier to the Comment column. Click [here](DataQualifiers_20220210.xlsx) [XLSX] to 
download the list of data qualifiers currently being used by RMN partners.

*	Leave missing data cells blank.

## Workflow

Click [here](Workflow_QC_report_20220824.pdf) [PDF] for recommendations on a workflow
for reviewing the QC reports.

If you have a backlog of data files from multiple deployments and are wondering 
how to most efficiently QC the files, [here](Workflow_DataPileup_20220824.pdf) [PDF] 
is a recommended workflow.

Click [here](SiteVisitChecklist.zip) [ZIP] for a site visit checklist to help ensure 
that you do not forget to document information that is important for the data QC
process.

## Sensor configuration

Some people have had problems with air and water sensors being out of sync (
e.g., one records at 11:00 and the other records at 11:07). If you are deploying
air and water sensors at a site, make sure they are recording at the same time. 
This will make data processing faster and easier. If you are using Onset HOBO 
sensors, click [here](HOBO_ConfigLaunch_20170803.pdf) [PDF] for tips on configuring 
them in a way that ensures they will record at the same time. 

Another issue that sometimes occurs is data overlap (where more than one file 
has measurements covering part of the same time periods). If you are using Onset
HOBO sensors, click [here](HOBO_DataDownload_20170823.pdf) [PDF] for procedures to 
follow during data download to clear sensor memory and avoid overlapping data.

## Accuracy checks

Accuracy checks are comparisons of discrete or in situ measurements taken in the
lab and/or in the field with sensor measurements from the closest date/time. The
sensor measurement should be within the accuracy quoted by the manufacturer (
e.g., ±0.2°C if you are using the Onset HOBO proV2 sensor). Accuracy checks are 
used to validate your data, and in some cases, correct for sensor drift. Click 
[here](EXAMPLE_AccuracyCheckWkst.xlsx) [XLSX] to download an example of an accuracy 
check worksheet being kept by an RMN partner. 

## Visual checks of time series plots

Visual checks of time series plots are an important part of the QC process. 
Click [here](PlotQC_WatchList_20220824.pdf) [PDF] to see a compilation of patterns to 
watch for when interpreting the plots. They include ice cover, beaver activity, 
leaf packs, dewatering, and dead batteries. We will continue to add slides to 
this as we receive materials.

## Checking sensor data against other data sources

This is optional but encouraged if time permits. Click [here](Daymet_Wx_Gage.zip) [ZIP] for instructional 
materials from David Smith (Kentucky Division of Water) on how he has been 
downloading data from nearby weather stations and USGS gages, as well as modeled
air temperature and precipitation data from Daymet (
<a href="https://daymet.ornl.gov/getdata" data-once="external-links protected-links" target="_blank">https://daymet.ornl.gov/getdata<svg class="icon icon--exit is-spaced-before" role="img"> == $0 <title>Exit EPA's website</title><use href="https://www.epa.gov/themes/epa_theme/images/sprite.svg#launch"></use></svg></a>
), and comparing those data to sensor measurements as part of his QC process.
